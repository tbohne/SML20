%------------------------------------------------
%	PACKAGES AND THEMES
%------------------------------------------------

% this is a 4:3 layout.
\documentclass{beamer}
% for 16:9 use this command:
% \documentclass[aspectratio=169]{beamer}

\mode<presentation> {
\usetheme{metropolis}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{navigation symbols}{} % hide navigation symbols
}

\usepackage{graphicx} % images
\usepackage{algorithm2e}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\usepackage{algpseudocode}
\usepackage{booktabs} % allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{listings} % code
\usepackage{pgf,tikz} % drawing
\usepackage{pifont} % new symbols
\usepackage{hyperref} % pretty links
% \usepackage{algorithmicx}
% \usepackage{algpseudocode}
% \usepackage[linesnumbered,ruled]{algorithm2e}

\usepackage{lmodern}
\usepackage{subcaption}
\usepackage{textcomp}
% \usepackage{array}
% \usepackage{longtable}
% \usepackage{verbatim}
%\usepackage{tabularx}
\captionsetup[figure]{font=footnotesize}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
% \usepackage{comment}
% \usepackage{enumitem}
% \usepackage[binary-units=true]{siunitx}
% \usepackage{thmtools}
\usepackage{csquotes}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{automata,positioning}

% color settings for links
\hypersetup{
    colorlinks=true,
    urlcolor=blue,
    linkcolor=black,
    citecolor=green!50!black
}

\definecolor{mygreen}{RGB}{1,135,1}

\newcommand{\cmark}{\ding{51}}  % checkmark
\newcommand{\xmark}{\ding{55}}  % xmark
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}

\setbeamerfont{bibliography item}{size=\footnotesize}
\setbeamerfont{bibliography entry author}{size=\footnotesize}
\setbeamerfont{bibliography entry title}{size=\footnotesize}
\setbeamerfont{bibliography entry location}{size=\footnotesize}
\setbeamerfont{bibliography entry note}{size=\footnotesize}

% \useoutertheme{miniframes} % navigation design
\useinnertheme{circles} % use non shiny circles (itemize, etc.)

% Main slide colors
% dunkel, hell, mittel
% \definecolor{pale}{RGB}{232, 236, 237}
% \definecolor{prim}{RGB}{53, 109, 120}
% \definecolor{sec}{RGB}{104, 170, 183}
% \definecolor{tert}{RGB}{109, 155, 168}
% \definecolor{quat}{RGB}{9, 59, 68}

\definecolor{pale}{RGB}{255, 255, 255}
% \definecolor{prim}{RGB}{153, 194, 173}
% good: \definecolor{prim}{RGB}{27, 33, 42}
\definecolor{prim}{RGB}{32, 43, 50}
\definecolor{sec}{RGB}{217, 232, 224}
\definecolor{tert}{RGB}{0, 82, 41}
% save
\definecolor{quat}{RGB}{0, 82, 41}

\setbeamercolor{palette primary}{bg=prim,fg=pale}
\setbeamercolor{palette secondary}{bg=sec,fg=pale}
\setbeamercolor{palette tertiary}{bg=tert,fg=pale}
\setbeamercolor{palette quaternary}{bg=quat,fg=pale}
\setbeamercolor{structure}{fg=prim} % itemize, enumerate, etc
\setbeamercolor{section in toc}{fg=prim} % TOC sections

% Block colors
\definecolor{example_color}{RGB}{93, 137, 98}
\definecolor{alert_color}{RGB}{175, 79, 72}

\setbeamercolor{normal text}{fg=prim!20!black,bg=pale!25!white}
\setbeamercolor{alerted text}{fg=alert_color!25!black}
\setbeamercolor{example text}{fg=example_color!25!black}

\setbeamercolor{block title example}{fg=white,bg=example_color}
\setbeamercolor{block body example}{fg=black,bg=example_color!10!white}
\setbeamercolor{block title alerted}{fg=white,bg=alert_color}
\setbeamercolor{block body alerted}{fg=black,bg=alert_color!10!white}

% Override palette coloring
\setbeamercolor{subsection in head/foot}{bg=quat,fg=pale}

\setbeamertemplate{frametitle}{%
    \nointerlineskip%

    \begin{beamercolorbox}[wd=\paperwidth,ht=2.5ex,dp=1ex]{frametitle}
        \hspace*{1ex}\insertframetitle%
        \ifx\insertframesubtitle@empty\else%
        {~\tiny\textcolor{quat!35!black}{\insertframesubtitle}}%
        \fi%
    \end{beamercolorbox}%
}

% math-command for bigger norm
\newcommand\norm[1]{\left\lVert#1\right\rVert}

% use this to include other files
% in this case style definitions for code
% alternative: \include{dateiname}
\input{listings_style.tex}

\lstset{style=latex}

%------------------------------------------------
%	TITLE PAGE
%------------------------------------------------

\selectlanguage{ngerman}
\title[]{Robustness \& Graph (Convolutional) Neural Networks}

\author{Tim Bohne}
\institute[]
{
\textit{Machine Learning Seminar 20/21}
\medskip
}
\date{\today}

% make slide at the beginnig of each section
\AtBeginSection[]{
{\setbeamercolor{background canvas}{bg=white}}}

% where images are locatied
\graphicspath{{./images/}}

\begin{document}

\begin{frame}[plain] % plain slides dont have navigation bars etc.
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Übersicht} % table of contents slide
\tableofcontents
\end{frame}

%------------------------------------------------
\section{Motivation}
%------------------------------------------------

\begin{frame}
  \frametitle{Motivation}
  \textbf{Motivationen für Graph Neural Networks:}
  \begin{enumerate}
    \item Convolutional Neural Networks (CNNs)
    \item Graph Embedding
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Convolutional Neural Networks (CNNs)}
  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/CNN.png}
    \caption*{Convolutional Neural Network \cite{Zschech2020}}
  \end{figure}
  \begin{itemize}
    \item \textbf{Feature-Learning}\newline Sequenz aus Convolutional- und Pooling-Layern
    \item \textbf{Classification}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Convolutional Neural Networks (CNNs)}
  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/imagenet.png}
    \caption*{ \cite{Giro-o-Nieto}}
  \end{figure}
  Hier sind CNNs sehr erfolgreich!
\end{frame}

\begin{frame}
  \frametitle{Convolutional Neural Networks (CNNs)}
  \textbf{Problem}: CNNs funktionieren nur mit Euklidischen Datenstrukturen (Bilder, Text), nicht mit Graphen!
  
    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/mario.png}
        \caption*{Pixelmatrix \cite{Mario}}
      \end{subfigure}
      \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/convolution.png}
        \caption*{Convolution \cite{Convolution}}
      \end{subfigure}
    \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Graph Embedding}

  Übersetze Graph-Struktur in niedrigdimensionalen Vektor

  \begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{img/graph_embedding.png}
    \caption*{ \cite{}}
  \end{figure}

\end{frame}

%------------------------------------------------
\section{Graph Neural Networks (GNNs)}
%------------------------------------------------

\begin{frame}
  \frametitle{Graph Neural Networks (GNNs)}
  \textbf{Ermöglichen Machine Learning auf Graphen, z.B.:}
  \begin{itemize}
    \item Modellierung physikalischer Systeme
    \item Lernen molekularer Fingerabdrücke
    \item Kontrollierung von Verkehrsnetzen
    \item Freunde in sozialen Netzwerken empfehlen
  \end{itemize}
  \begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{img/social_graph.png}
    \caption*{Soziales Netzwerk \cite{Facebook}}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Graph Neural Networks (GNNs)}
  \textbf{Typische Aufgaben für GNNs:}
  \begin{itemize}
    \item Semi-Supervised Node Classification
    \item Link Prediction
    \item Clustering
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Graph Neural Networks (GNNs)}
  Graph $\boldsymbol{G = (X, A)}$\newline
  $\boldsymbol{X}:$ Knoten - Personen in sozialem Netzwerk\newline
  $\boldsymbol{A}:$ Kanten - Beziehungen zwischen Personen
  \begin{figure}
    \centering
    \includegraphics[width=0.575\textwidth]{img/graph.png}
    \caption*{ \cite{}}
  \end{figure}
  \textbf{Ziel}: Lerne node embedding $\boldsymbol{h_v}$ für jeden Knoten $\boldsymbol{v} \in \boldsymbol{X}$ um 
  einem Output $\boldsymbol{o_v}$ zu generieren, z.B. das vorhergesagte Label
\end{frame}

\begin{frame}
  \frametitle{Graph Neural Networks (GNNs)}

  $2$ wichtige Funktionen ($x$: Input Feature, $h$: Hidden State):
  \begin{enumerate}
    \item \textbf{node embedding:} $\quad\quad h_v = f(x_v, x_{co[v]}, h_{ne[v]}, x_{ne[v]})$
    \item \textbf{output embedding:} $\quad\thinspace o_v = g(h_v, x_v)$
  \end{enumerate}

  Iteratives State-Update: $H^{t+1} = F(H^t, X)$

  Lerne Parameter von $f$ und $g$:

  \textbf{Loss Term:} $\sum_{i=1}^p (t_i - o_i)$

  \textbf{Lernmethode}: Gradient Descent
\end{frame}

\begin{frame}
  \frametitle{Graph Convolutional Networks (GCNs)}

  \textbf{Input:} Features $X$, Adjazenzmatrix $A$\newline
  \textbf{Output:} Feature-Vektor für jeden Knoten
  \begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{img/GCN.png}
    \caption*{ \cite{}}
  \end{figure}
  Anschließend Node-Classification basierend auf den Output-Features
\end{frame}

\begin{frame}
  \frametitle{Graph Convolutional Networks (GCNs)}

  Standard Convolution kann nicht für Graphen definiert werden!

  Lösung: Embeddings (spectral / spatial)

  Approximierte \textquote{Graph-Convolution} (Kipf et al.):

  $\boldsymbol{H^{(l+1)}} = \sigma [\boldsymbol{\hat{D}}^{- \frac{1}{2}} \boldsymbol{\hat{A}} \boldsymbol{\hat{D}}^{- \frac{1}{2}} \boldsymbol{H^{(l)}} \boldsymbol{W^{(l)}}]$

\end{frame}

%------------------------------------------------
\section{Robustheit}
%------------------------------------------------

\begin{frame}
  \frametitle{Robustheit von Machine Learning Modellen}

  Machine Learning Modelle sind i.A. anfällig für \textquote{Adversarial Attacks}!

  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/adversarial.png}
    \caption*{Convolutional Neural Network \cite{}}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Robustheit von GNNs}
  Dies gilt auch für GNNs, wobei sich zwei Arten von Angriffen unterscheiden lassen:

  \begin{itemize}
    \item Manipulation der Knoten-Attribute
    \item Manipulation der Graph-Struktur
  \end{itemize}

  \begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{img/adversarial_GNN.png}
    \caption*{ \cite{}}
  \end{figure}

\end{frame}

\begin{frame}
  \frametitle{Robustheit von GNNs}
  \textbf{3 Phasen in der Literatur:}
  \begin{enumerate}
    \item GNNs anfällig für \textquote{Adversarial Attacks}
    \item Verteidigungsmechanismen für bestimmte Szenarien
    \item Beweisbare Garantien für die Robustheit bestimmter Modelle
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Semi-Supervised Node Classification}

  Graph $\boldsymbol{G} = (\boldsymbol{A}, \boldsymbol{X})$ $\quad$ Zielknoten $\boldsymbol{t}$ $\quad$ trainierbare Parameter $\boldsymbol{\theta}$\newline
  $\boldsymbol{A}$: Adjazenzmatrix, $\boldsymbol{X}$: Knoten-Features\newline

  $\boldsymbol{V}$: Knotenmenge\newline
  $\boldsymbol{V_L} \subseteq \boldsymbol{V}$: Teilmenge der gelabelten Knoten\newline

  $\boldsymbol{\mathcal{T}(A)}$: \textquote{Message-Passing-Matrix} - wie Aktivierungen durch das GNN propagiert werden
  $\rightarrow$ Transformation der Adjazenzmatrix\newline

  \textbf{Cross-Entropy-Loss Minimierung}:\newline
  Lerne $\boldsymbol{\theta}$ unter Verwendung der $\boldsymbol{V_L}$\newline

  \textbf{Ziel}: Den Knoten Labels zuweisen

\end{frame}

%------------------------------------------------
\subsection{GNNs: Manipulation der Knoten-Attribute}
%------------------------------------------------

\begin{frame}
  \frametitle{Robustheit von GNNs}
  \textbf{Zertifizierte Robustheit gegenüber Manipulationen der Knoten-Attribute:}\newline
  Wie lässt sich sicherstellen, dass kleine Änderungen am Input keine dramatischen Auswirkungen auf den Output haben?
\end{frame}

\begin{frame}
  \frametitle{Zertifizierung der Robustheit bereits trainierter GNNs}

  \textbf{Ziel}: Zertifikat für Knoten $\boldsymbol{t}$ bedeutet, dass die Vorhersage für $\boldsymbol{t}$ sich nach zulässigen Manipulationen nicht ändert.\newline
  $\rightarrow$ definiertes Angriffsmodell\newline

  \textquote{\textbf{Worst-Case-Margin}} $\boldsymbol{m^t}$ für Knoten $\boldsymbol{t}$ zwischen den Klassen $\boldsymbol{y}$ und $\boldsymbol{y^{\ast}}$ 
  basierend auf Angriffsmodell:

  \begin{gather} 
        m^t (y^*, y) := \min_{\tilde{X}} f_{\theta}^t(\tilde{X}, A)_{y^*} - f_{\theta}^t(\tilde{X}, A)_y \nonumber \\
        s.t. \quad \tilde{X} \in zul. Manipulationen \nonumber
    \end{gather}
\end{frame}

\begin{frame}
  \frametitle{High-Level Idee}

  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{1\textwidth}
      \centering
      \includegraphics[width=0.75\textwidth]{img/before_pert.png}
      \caption*{Vor der Manipulation \cite{}}
    \end{subfigure}
    \par\bigskip
    \begin{subfigure}[b]{1\textwidth}
      \centering
      \includegraphics[width=0.75\textwidth]{img/after_pert.png}
      \caption*{Nach der Manipulation \cite{}}
    \end{subfigure}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Lösung des Optimierungsproblems}
  Optimierungsproblem \textbf{nicht effizient lösbar}: Diskrete Domäne + Nicht-konvexe Aktivierungsfunktion\newline

  \textbf{Lösung}: Mehrere Relaxationen (des Modells und der Daten) um Schranken für den worst-case Fall für das definierte Angriffsmodell zu berechnen
\end{frame}

\begin{frame}
  \frametitle{Training mit dem Ziel der Robustheit}

  \textbf{Ziel}: Erreiche beweisbare Robustheit durch Training\newline
  $\rightarrow$ Optimiere bezüglich Robustheit

  \textbf{Robust Hinge Loss}
  \begin{itemize}
    \item nutzt \textquote{unlabeled nodes} um \textquote{over-confidence} zu vermeiden
    \item Zielfunktion für Training verwendet:
    \begin{itemize}
      \item relaxierte Version des GNN um Robustheit sicherzustellen
      \item exakte Version für die \textquote{Classification}
    \end{itemize}
  \end{itemize}  

  Der Ansatz liefert die Möglichkeit, mit Standardsoftware robuste GNNs zu trainieren!

  Die Qualität der \textquote{Classification}-Ergebnisse ist davon nicht betroffen!
\end{frame}

\begin{frame}
  \frametitle{Training mit dem Ziel der Robustheit}
  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/robust_training.png}
    \caption*{ \cite{}}
  \end{figure}
  \begin{itemize}
    \item Nur wenige Knoten nicht zertifizierbar
    \item Traditionell trainierte GNNs nur robust bei sehr wenigen Manipulationen
  \end{itemize}
\end{frame}

%------------------------------------------------
\subsection{GNNs: Manipulation der Graph-Struktur}
%------------------------------------------------

\begin{frame}
  \frametitle{Robustheit von GNNs}
  \textbf{Zertifizierte Robustheit gegenüber Manipulationen der Graph-Struktur:}\newline
  Besonders problematisch, weil das \textquote{Message Passing Scheme} verändert wird

  Das Problem wird als \textquote{Jointly constrained bilinear Program} formuliert und es wird ein Branch-and-Bound-Ansatz vorgestellt, der
  untere Schranken für den optimalen Zielfunktionswert liefert.
\end{frame}

\begin{frame}
  \frametitle{Angriffsmodell}
  Angreifer können neue Kanten in den Graphen einfügen, z.B. Likes in Social Media!
  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/high_level_graph_pert.png}
    \caption*{ \cite{}}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Idee}
  Ein Zertifikat bedeutet, dass sich die Prediction für einen Knoten nicht ändert, wenn ein Angreifer Kanten hinzufügt.
\end{frame}

\begin{frame}
  \frametitle{Optimierungsproblem}

  \begin{itemize}
    \item bereits trainiertes GNN mit Parametern $\theta$
    \item Input-Graph repräsentiert durch Matrix $A$ möglicherweise manipuliert
    \item $A$ ist von der \textquote{sauberen} Variante $A^{\ast}$ durch eine Menge zulässiger Manipulationen der Graph-Struktur erreichbar
  \end{itemize}

  \begin{gather} 
    m^t (y^*, y) := \min_{\tilde{A}} f_{\theta}^t(X, \mathcal{T}(\tilde{A})_{y^*} - f_{\theta}^t(X, \mathcal{T}(\tilde{A}))_y \nonumber \\
    s.t. \quad \tilde{A} \in zul. Manipulationen \nonumber
\end{gather}
  GNN robust bzgl. des Angriffsmodells für den Knoten $t$, wenn $m^t (y^*, y) > 0 \forall y \neq y^{\ast}$
\end{frame}

\begin{frame}
  \frametitle{Optimierungsproblem}
  \textbf{Problem}: Erneut nicht effizient lösbar!\newline
  $\rightarrow$ berechne erneut untere Schranken statt optimaler Zielfunktionswerte!\newline

  $3$ Schritte:
  \begin{enumerate}
    \item Binäre Adjazenzmatrix durch kontinuierliche Message-Passing-Matrix ersetzen
    \item Relaxation der Aktivierungsfuntion des GNN
    \item Formulierung als Jointly-Constrained-Bilinear-Program und Lösung durch Branch-and-Bound
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Ergebnis}
  \begin{figure}
    \centering
    \includegraphics[width=0.65\textwidth]{img/graph_struct_pert_res.png}
    \caption*{ \cite{}}
  \end{figure}
\end{frame}

%------------------------------------------------
\section{Fazit / Ausblick}
%------------------------------------------------

\begin{frame}
  \frametitle{Fazit}

  \begin{itemize}
    \item GNNs sind sehr erfolgreich in einer Vielzahl von praktischen Anwendungen einsetzbar
    \item GNNs sind nicht robust - anfällig für Manipulationen
    \begin{itemize}
      \item der Knoten-Attribute
      \item der Graph-Struktur
    \end{itemize}
    \item Um GNNs in (sicherheitskritischen) praktischen Anwendungen nutzen zu können, ist ein bestimmtes Maß an Robustheit nötig
    \item Beweisbare Garantien für die (Nicht-)Robustheit von GNNs sind möglich und nötig - erste Ansätze gesehen
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Ausblick}

  \begin{itemize}
    \item Viel Spielraum für Generalisierungen
    \item Trainingmethoden, die Robustheit explizit als Optimierungsziel enthalten
    \item Robustheitsgarantien für Attribut- und Struktur-Manipulationen
    \item Grundsätzliches Verständnis - was macht Manipulationen schädlich?
    \item Allgemeinere Angriffsmodelle
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Was macht Manipulationen schädlich?}

  Mehrere Ideen / Ansätze

  \begin{itemize}
    \item Graphen, die reale Probleme repräsentieren besitzen bestimmte strukturelle Gemeinsamkeiten, die manipulierte Graphen verletzen
    \item Statistisch signifikante strukturelle Attribute in Manipulationen entdecken
    \item Wahrscheinlichkeit dafür, dass bestimmte gegebene Manipulationen tatsächlich schädlich sind
  \end{itemize}

  Was hätten wir davon?

  \begin{itemize}
    \item Angriffsmodelle verallgemeinern
    \item Manipulationen anhand ihrer Eigenschaften erkennen und damit verhindern $\rightarrow$ Robustheit
  \end{itemize}

\end{frame}

\begin{frame}[allowframebreaks]
  \bibliographystyle{plain}
  \bibliography{sources.bib}
\end{frame}

\end{document}
